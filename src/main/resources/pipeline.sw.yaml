id: pipeline
version: '1.0'
specVersion: '0.8'
name: Inference Pipeline
description: Inference Pipeline with SonataFlow
start: Imports
functions:
  - name: python
    type: custom
    operation: script:python
  - name: invoke_kserve
    operation: model_openapi.yaml#infer
states:
  - name: Imports
    type: operation
    actions:
      - functionRef:
          refName: python
          arguments:
            script: |
              import sys
              sys.path.append('./src/main/resources/python')
              from coco_to_kserve import to_kserve
              from response_handler import handle_response
    transition: Inference pre-processing
  - name: Inference pre-processing
    type: operation
    actions:
      - functionRef:
          refName: python
          arguments:
            script: "kserve_payload = to_kserve(image)"
            image: ".image"
    stateDataFilter:
      output: "{kserve_payload:$WORKFLOW.python.kserve_payload}"
    transition: Invoke KServe
  - name: Invoke KServe
    type: operation
    actions:
      - functionRef:
          refName: invoke_kserve
          arguments:
            inputs: .kserve_payload.inputs
    stateDataFilter:
      output: '{kserve_response: .outputs, image: .image}'
    transition: Inference post-processing
  - name: Inference post-processing
    type: operation
    actions:
      - functionRef:
          refName: python
          arguments:
            script: "output_image = handle_response(image, kserve_response, output_image)"
            image: ".image"
            kserve_response: ".kserve_response"
            output_image: ".output_image.jpg"
    stateDataFilter:
      output: "{output_image:$WORKFLOW.python.output_image}"
    end: true
